package org.spoofax.jsglr2.integrationtest.features;

import static mb.jsglr.shared.IToken.Kind.*;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;
import java.util.stream.Collectors;
import java.util.stream.Stream;

import org.junit.jupiter.api.DynamicTest;
import org.junit.jupiter.api.TestFactory;
import org.spoofax.jsglr2.integrationtest.BaseTestWithSdf3ParseTables;
import org.spoofax.jsglr2.integrationtest.TokenDescriptor;
import org.spoofax.terms.ParseError;

public class EmojiTest extends BaseTestWithSdf3ParseTables {

    public EmojiTest() {
        super("emoji.sdf3");
    }

    @TestFactory public Stream<DynamicTest> testCorrectEmoji() throws ParseError {
        return testSuccessByExpansions("ðŸ˜„ðŸ˜‡ðŸ˜¹ðŸ™„ðŸ˜ƒðŸ˜€", "[Var(\"ðŸ˜„ðŸ˜‡ðŸ˜¹ðŸ™„ðŸ˜ƒðŸ˜€\")]");
    }

    @TestFactory public Stream<DynamicTest> testWrongEmoji() throws ParseError {
        // Note that the last emoji is a single-character emoji, i.e. "\u2728"
        return Stream.of(testParseFailure("ðŸŽ‰"), testParseFailure("ðŸš€"), testParseFailure("âœ¨"))
            .flatMap(stream -> stream);
    }

    @TestFactory public Stream<DynamicTest> testSingleSurrogate() throws ParseError {
        // This is the first UTF-16 surrogate character for the correct emoji (full encoding would be "\uD83D\uDE00").
        // As this is not a complete code point, it should fail.
        return testParseFailure("\uD83D");
    }

    @TestFactory public Stream<DynamicTest> testLetters() throws ParseError {
        return testParseFailure("Hello World!");
    }

    @TestFactory public Stream<DynamicTest> tokenizationTestSingle() throws ParseError {
        return testTokens("ðŸ˜‡ðŸ˜¹ðŸ˜„",
            Collections.singletonList(new TokenDescriptor("ðŸ˜‡ðŸ˜¹ðŸ˜„", TK_IDENTIFIER, 0, 1, 1, "ID", null)));
    }

    @TestFactory public Stream<DynamicTest> tokenizationTestAdd() throws ParseError {
        return testTokens("ðŸ˜‡ âž• ðŸ˜„",
            Arrays.asList(new TokenDescriptor("ðŸ˜‡", TK_IDENTIFIER, 0, 1, 1, "ID", null),
                new TokenDescriptor(" ", TK_LAYOUT, 2, 1, 2, "Exp", "Add"),
                new TokenDescriptor("âž•", TK_IDENTIFIER, 3, 1, 3, "PLUS", null),
                new TokenDescriptor(" ", TK_LAYOUT, 4, 1, 4, "Exp", "Add"),
                new TokenDescriptor("ðŸ˜„", TK_IDENTIFIER, 5, 1, 5, "ID", null)));
    }

    @TestFactory public Stream<DynamicTest> tokenizationTestMultilineWithEmpty() throws ParseError {
        List<TokenDescriptor> expectedAllTokens =
            Arrays.asList(new TokenDescriptor("ðŸ˜‡", TK_IDENTIFIER, 0, 1, 1, "ID", null),
                new TokenDescriptor(" ", TK_LAYOUT, 2, 1, 2, null, "[]"),
                new TokenDescriptor("\n", TK_KEYWORD, 3, 1, 3, null, "[]"),
                new TokenDescriptor("", TK_NO_TOKEN_KIND, 4, 2, 1, "Exp", "Empty"),
                new TokenDescriptor("\n", TK_KEYWORD, 4, 2, 1, null, "[]"),
                new TokenDescriptor(" ", TK_LAYOUT, 5, 3, 1, null, "[]"),
                new TokenDescriptor("ðŸ˜„", TK_IDENTIFIER, 6, 3, 2, "ID", null));
        List<TokenDescriptor> expectedTokens =
            expectedAllTokens.stream().filter(t -> t.kind != TK_NO_TOKEN_KIND).collect(Collectors.toList());
        return testTokens("ðŸ˜‡ \n\n ðŸ˜„", expectedTokens, expectedAllTokens);
    }

    @TestFactory public Stream<DynamicTest> testEmojiIncremental() throws ParseError {
        return testIncrementalSuccessByExpansions(new String[] { "ðŸ˜‡ âž• ðŸ˜„ðŸ˜„", "ðŸ˜‡ðŸ˜‡  âž• ðŸ˜„" },
            new String[] { "[Add(Var(\"ðŸ˜‡\"),\"âž•\",Var(\"ðŸ˜„ðŸ˜„\"))]", "[Add(Var(\"ðŸ˜‡ðŸ˜‡\"),\"âž•\",Var(\"ðŸ˜„\"))]" });
    }

}
